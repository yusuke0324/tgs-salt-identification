{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import train_util\n",
    "import util\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3887/3887 [00:31<00:00, 122.57it/s]\n"
     ]
    }
   ],
   "source": [
    "X, X_feat, Y, Y_no_sult = train_util.get_data(size=(128, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "# dense_model = keras.applications.densenet.DenseNet121(include_top=False, weights=None, input_tensor=input_tensor, pooling=None)\n",
    "xception_model = keras.applications.Xception(weights='imagenet',include_top=False, input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add FC layer\n",
    "x = xception_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "# top_model = Sequential()\n",
    "# top_model.add(Flatten(input_shape=dense_model.output_shape[1:]))\n",
    "# top_model.add(Dense(256, activation='relu', input_dim=feat_shape[1]* feat_shape[2]*feat_shape[3]))\n",
    "# top_model.add(Dropout(0.5))\n",
    "# top_model.add(Dense(128, activation='relu'))\n",
    "# top_model.add(Dropout(0.5))\n",
    "# top_model.add(Dense(2, activation='softmax'))\n",
    "# top_model.add(Dense(1, activation='sigmoid'))\n",
    "model = Model(xception_model.input, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, x_feat_train, x_feat_test, y_train, y_test = train_test_split(X, X_feat, Y_no_sult, test_size=0.1, random_state=43)\n",
    "y_train = np_utils.to_categorical(y_train, 2)\n",
    "y_test = np_utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "data_gen_args = {\n",
    "                             'vertical_flip': True,\n",
    "                             'horizontal_flip': True\n",
    "}\n",
    "# apply same args for generator\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# set same seed number and apply it to X and Y (mask)\n",
    "seed = 1\n",
    "image_datagen.fit(x_train, augment=True, seed=seed)\n",
    "\n",
    "train_gen = image_datagen.flow(x_train, y_train, seed=seed, batch_size=32, shuffle=True)\n",
    "\n",
    "# train_gen = zip(image_generator, feature_generator,  mask_generator)\n",
    "val_gen = (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features = xception_model.predict(x_train)\n",
    "# feat_shape = np.array(train_features.shape)\n",
    "# validation_features = xception_model.predict(x_test)\n",
    "\n",
    "# train_features = np.reshape(train_features, (feat_shape[0], feat_shape[1]*feat_shape[2]*feat_shape[3]))\n",
    "# validation_features = np.reshape(validation_features, (validation_features.shape[0], feat_shape[1]*feat_shape[2]*feat_shape[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 63, 63, 32)   864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 63, 63, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 63, 63, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 61, 61, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 61, 61, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 61, 61, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 61, 61, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 61, 61, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 61, 61, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 31, 31, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 31, 31, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 31, 31, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 31, 31, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 31, 31, 128)  0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 31, 31, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 31, 31, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 31, 31, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 256)  32768       add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 16, 16, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 16, 16, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 16, 16, 256)  0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 16, 16, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 16, 16, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 728)    186368      add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 728)    2912        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 8, 8, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 4, 1024)   745472      add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 1024)   4096        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 2)            4098        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 20,865,578\n",
      "Trainable params: 20,811,050\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 17s - loss: 0.5922 - acc: 0.7188 - val_loss: 0.4694 - val_acc: 0.8329\n",
      "Finished epoch: 0\n",
      "{'val_loss': 0.4694123709416328, 'val_acc': 0.8329048844719914, 'loss': 0.5922468062490225, 'acc': 0.71875}\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46941, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 2/100\n",
      " - 11s - loss: 0.4760 - acc: 0.8379 - val_loss: 0.3632 - val_acc: 0.8689\n",
      "Finished epoch: 1\n",
      "{'val_loss': 0.3632231020682269, 'val_acc': 0.8688946015424165, 'loss': 0.4760086443275213, 'acc': 0.837890625}\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.46941 to 0.36322, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 3/100\n",
      " - 11s - loss: 0.3986 - acc: 0.8571 - val_loss: 0.2992 - val_acc: 0.8869\n",
      "Finished epoch: 2\n",
      "{'val_loss': 0.2991936009540043, 'val_acc': 0.8868894601542416, 'loss': 0.39689101014070644, 'acc': 0.8582834332527038}\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36322 to 0.29919, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 4/100\n",
      " - 10s - loss: 0.3405 - acc: 0.8748 - val_loss: 0.2564 - val_acc: 0.8920\n",
      "Finished epoch: 3\n",
      "{'val_loss': 0.2563819617109617, 'val_acc': 0.8920308483290489, 'loss': 0.3393415878870768, 'acc': 0.8742514967680454}\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.29919 to 0.25638, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 5/100\n",
      " - 11s - loss: 0.3151 - acc: 0.8818 - val_loss: 0.2395 - val_acc: 0.8946\n",
      "Finished epoch: 4\n",
      "{'val_loss': 0.23945084375097084, 'val_acc': 0.8946015424164524, 'loss': 0.3151213452219963, 'acc': 0.8818359375}\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.25638 to 0.23945, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 6/100\n",
      " - 11s - loss: 0.2811 - acc: 0.8955 - val_loss: 0.2161 - val_acc: 0.9100\n",
      "Finished epoch: 5\n",
      "{'val_loss': 0.21607253694748818, 'val_acc': 0.910025706940874, 'loss': 0.28112057875841856, 'acc': 0.8955078125}\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.23945 to 0.21607, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 7/100\n",
      " - 11s - loss: 0.2794 - acc: 0.8945 - val_loss: 0.2123 - val_acc: 0.9049\n",
      "Finished epoch: 6\n",
      "{'val_loss': 0.21233262916533682, 'val_acc': 0.9048843187660668, 'loss': 0.2793952417559922, 'acc': 0.89453125}\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.21607 to 0.21233, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 8/100\n",
      " - 11s - loss: 0.2609 - acc: 0.8984 - val_loss: 0.1959 - val_acc: 0.9049\n",
      "Finished epoch: 7\n",
      "{'val_loss': 0.19590821038634734, 'val_acc': 0.9048843187660668, 'loss': 0.2608802714385092, 'acc': 0.8984375}\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.21233 to 0.19591, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 9/100\n",
      " - 10s - loss: 0.2268 - acc: 0.9109 - val_loss: 0.1869 - val_acc: 0.9126\n",
      "Finished epoch: 8\n",
      "{'val_loss': 0.1868502299629324, 'val_acc': 0.912596401181503, 'loss': 0.22708205643766177, 'acc': 0.9111776444726362}\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.19591 to 0.18685, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 10/100\n",
      " - 11s - loss: 0.2120 - acc: 0.9209 - val_loss: 0.1856 - val_acc: 0.9152\n",
      "Finished epoch: 9\n",
      "{'val_loss': 0.18561049529703233, 'val_acc': 0.9151670952689065, 'loss': 0.21196575742214918, 'acc': 0.9208984375}\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.18685 to 0.18561, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 11/100\n",
      " - 11s - loss: 0.2280 - acc: 0.9092 - val_loss: 0.1800 - val_acc: 0.9152\n",
      "Finished epoch: 10\n",
      "{'val_loss': 0.1799896598475145, 'val_acc': 0.9151670952689065, 'loss': 0.22798352735117078, 'acc': 0.9091796875}\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.18561 to 0.17999, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 12/100\n",
      " - 11s - loss: 0.1939 - acc: 0.9307 - val_loss: 0.1741 - val_acc: 0.9229\n",
      "Finished epoch: 11\n",
      "{'val_loss': 0.17406439559012268, 'val_acc': 0.922879177377892, 'loss': 0.19393194653093815, 'acc': 0.9306640625}\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.17999 to 0.17406, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 13/100\n",
      " - 11s - loss: 0.1953 - acc: 0.9245 - val_loss: 0.1761 - val_acc: 0.9203\n",
      "Finished epoch: 12\n",
      "{'val_loss': 0.17613714167268846, 'val_acc': 0.9203084832904884, 'loss': 0.18912925126547822, 'acc': 0.9271457087018057}\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/100\n",
      " - 11s - loss: 0.2088 - acc: 0.9170 - val_loss: 0.1657 - val_acc: 0.9332\n",
      "Finished epoch: 13\n",
      "{'val_loss': 0.1657243969354654, 'val_acc': 0.9331619538807318, 'loss': 0.20881842984817922, 'acc': 0.9169921875}\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.17406 to 0.16572, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 15/100\n",
      " - 11s - loss: 0.1861 - acc: 0.9238 - val_loss: 0.1625 - val_acc: 0.9203\n",
      "Finished epoch: 14\n",
      "{'val_loss': 0.16245371474858114, 'val_acc': 0.9203084834437137, 'loss': 0.18613979767542332, 'acc': 0.923828125}\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.16572 to 0.16245, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 16/100\n",
      " - 11s - loss: 0.1747 - acc: 0.9268 - val_loss: 0.1738 - val_acc: 0.9280\n",
      "Finished epoch: 15\n",
      "{'val_loss': 0.17383046835124646, 'val_acc': 0.9280205657059245, 'loss': 0.1747009539976716, 'acc': 0.9267578125}\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/100\n",
      " - 10s - loss: 0.2001 - acc: 0.9160 - val_loss: 0.1655 - val_acc: 0.9306\n",
      "Finished epoch: 16\n",
      "{'val_loss': 0.165538381449974, 'val_acc': 0.9305912597933281, 'loss': 0.2027979385174677, 'acc': 0.9141716566866267}\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/100\n",
      " - 11s - loss: 0.1767 - acc: 0.9238 - val_loss: 0.1658 - val_acc: 0.9229\n",
      "Finished epoch: 17\n",
      "{'val_loss': 0.16583630002096564, 'val_acc': 0.9228791775311174, 'loss': 0.17665060702711344, 'acc': 0.923828125}\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/100\n",
      " - 11s - loss: 0.1697 - acc: 0.9258 - val_loss: 0.1610 - val_acc: 0.9306\n",
      "Finished epoch: 18\n",
      "{'val_loss': 0.1609687520559772, 'val_acc': 0.9305912597933281, 'loss': 0.1696615198161453, 'acc': 0.92578125}\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.16245 to 0.16097, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 20/100\n",
      " - 10s - loss: 0.1670 - acc: 0.9372 - val_loss: 0.1607 - val_acc: 0.9332\n",
      "Finished epoch: 19\n",
      "{'val_loss': 0.16074641018263172, 'val_acc': 0.9331619538807318, 'loss': 0.16336587422384236, 'acc': 0.9401197605980133}\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.16097 to 0.16075, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 21/100\n",
      " - 11s - loss: 0.1633 - acc: 0.9365 - val_loss: 0.1660 - val_acc: 0.9229\n",
      "Finished epoch: 20\n",
      "{'val_loss': 0.16596866374150646, 'val_acc': 0.9228791775311174, 'loss': 0.163316099322401, 'acc': 0.9365234375}\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/100\n",
      " - 11s - loss: 0.1432 - acc: 0.9434 - val_loss: 0.1693 - val_acc: 0.9229\n",
      "Finished epoch: 21\n",
      "{'val_loss': 0.16925127769803633, 'val_acc': 0.9228791775311174, 'loss': 0.14323264255654067, 'acc': 0.943359375}\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/100\n",
      " - 10s - loss: 0.1723 - acc: 0.9313 - val_loss: 0.1702 - val_acc: 0.9306\n",
      "Finished epoch: 22\n",
      "{'val_loss': 0.17021200788664634, 'val_acc': 0.9305912597933281, 'loss': 0.15846784754903492, 'acc': 0.9341317366459174}\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/100\n",
      " - 11s - loss: 0.1536 - acc: 0.9385 - val_loss: 0.1647 - val_acc: 0.9306\n",
      "Finished epoch: 23\n",
      "{'val_loss': 0.16472095404308681, 'val_acc': 0.9305912597933281, 'loss': 0.15363250207155943, 'acc': 0.9384765625}\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/100\n",
      " - 11s - loss: 0.1418 - acc: 0.9395 - val_loss: 0.1617 - val_acc: 0.9254\n",
      "Finished epoch: 24\n",
      "{'val_loss': 0.1616966493025537, 'val_acc': 0.925449871618521, 'loss': 0.141836415277794, 'acc': 0.939453125}\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/100\n",
      " - 10s - loss: 0.1300 - acc: 0.9549 - val_loss: 0.1645 - val_acc: 0.9332\n",
      "Finished epoch: 25\n",
      "{'val_loss': 0.1645047994076746, 'val_acc': 0.9331619538807318, 'loss': 0.1249991208612324, 'acc': 0.9560878241133547}\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/100\n",
      " - 11s - loss: 0.1400 - acc: 0.9414 - val_loss: 0.1657 - val_acc: 0.9203\n",
      "Finished epoch: 26\n",
      "{'val_loss': 0.16569558375905288, 'val_acc': 0.9203084834437137, 'loss': 0.1400128862587735, 'acc': 0.94140625}\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/100\n",
      " - 11s - loss: 0.1191 - acc: 0.9502 - val_loss: 0.1652 - val_acc: 0.9332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 27\n",
      "{'val_loss': 0.1651882622726166, 'val_acc': 0.9331619538807318, 'loss': 0.11909433320397511, 'acc': 0.9501953125}\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/100\n",
      " - 11s - loss: 0.1247 - acc: 0.9492 - val_loss: 0.1619 - val_acc: 0.9254\n",
      "Finished epoch: 28\n",
      "{'val_loss': 0.161942832880584, 'val_acc': 0.925449871618521, 'loss': 0.12474859732901677, 'acc': 0.94921875}\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/100\n",
      " - 11s - loss: 0.1372 - acc: 0.9558 - val_loss: 0.1698 - val_acc: 0.9332\n",
      "Finished epoch: 29\n",
      "{'val_loss': 0.1697505453558385, 'val_acc': 0.9331619538807318, 'loss': 0.12602702981816558, 'acc': 0.9590818364463166}\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/100\n",
      " - 11s - loss: 0.1259 - acc: 0.9482 - val_loss: 0.1680 - val_acc: 0.9306\n",
      "Finished epoch: 30\n",
      "{'val_loss': 0.16797175727650562, 'val_acc': 0.9305912597933281, 'loss': 0.12589008337818086, 'acc': 0.9482421875}\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/100\n",
      " - 11s - loss: 0.1410 - acc: 0.9492 - val_loss: 0.1684 - val_acc: 0.9357\n",
      "Finished epoch: 31\n",
      "{'val_loss': 0.16842148251888991, 'val_acc': 0.9357326479681354, 'loss': 0.1410176576464437, 'acc': 0.94921875}\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/100\n",
      " - 11s - loss: 0.0815 - acc: 0.9658 - val_loss: 0.1664 - val_acc: 0.9357\n",
      "Finished epoch: 32\n",
      "{'val_loss': 0.16640108088294767, 'val_acc': 0.9357326479681354, 'loss': 0.08147403039038181, 'acc': 0.9658203125}\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/100\n",
      " - 10s - loss: 0.1228 - acc: 0.9530 - val_loss: 0.1601 - val_acc: 0.9332\n",
      "Finished epoch: 33\n",
      "{'val_loss': 0.16008224118031694, 'val_acc': 0.9331619538807318, 'loss': 0.12083152195293746, 'acc': 0.9540918161293228}\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.16075 to 0.16008, saving model to ./log/2018_0728_1659/best_weights.hdf5\n",
      "Epoch 35/100\n",
      " - 11s - loss: 0.1033 - acc: 0.9570 - val_loss: 0.1610 - val_acc: 0.9332\n",
      "Finished epoch: 34\n",
      "{'val_loss': 0.1610126066330466, 'val_acc': 0.9331619538807318, 'loss': 0.10327055410016328, 'acc': 0.95703125}\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/100\n",
      " - 11s - loss: 0.0852 - acc: 0.9697 - val_loss: 0.1739 - val_acc: 0.9280\n",
      "Finished epoch: 35\n",
      "{'val_loss': 0.17387410324153066, 'val_acc': 0.9280205657059245, 'loss': 0.08519286738010123, 'acc': 0.9697265625}\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/100\n",
      " - 11s - loss: 0.0986 - acc: 0.9678 - val_loss: 0.1759 - val_acc: 0.9332\n",
      "Finished epoch: 36\n",
      "{'val_loss': 0.17585513171929013, 'val_acc': 0.9331619538807318, 'loss': 0.10016314310956739, 'acc': 0.9670658682634731}\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/100\n",
      " - 11s - loss: 0.1002 - acc: 0.9580 - val_loss: 0.1716 - val_acc: 0.9332\n",
      "Finished epoch: 37\n",
      "{'val_loss': 0.17160873793084702, 'val_acc': 0.9331619538807318, 'loss': 0.1001853090710938, 'acc': 0.9580078125}\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/100\n",
      " - 11s - loss: 0.0819 - acc: 0.9668 - val_loss: 0.1655 - val_acc: 0.9357\n",
      "Finished epoch: 38\n",
      "{'val_loss': 0.165496311871129, 'val_acc': 0.9357326479681354, 'loss': 0.0819169323076494, 'acc': 0.966796875}\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/100\n",
      " - 11s - loss: 0.0926 - acc: 0.9658 - val_loss: 0.1690 - val_acc: 0.9357\n",
      "Finished epoch: 39\n",
      "{'val_loss': 0.16896761268147467, 'val_acc': 0.9357326479681354, 'loss': 0.092613291926682, 'acc': 0.9658203125}\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/100\n",
      " - 11s - loss: 0.1033 - acc: 0.9616 - val_loss: 0.1658 - val_acc: 0.9409\n",
      "Finished epoch: 40\n",
      "{'val_loss': 0.16582976300796076, 'val_acc': 0.9408740361429425, 'loss': 0.09379481228287824, 'acc': 0.9650698603984125}\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/100\n",
      " - 11s - loss: 0.0749 - acc: 0.9727 - val_loss: 0.1680 - val_acc: 0.9409\n",
      "Finished epoch: 41\n",
      "{'val_loss': 0.1680123147130932, 'val_acc': 0.9408740361429425, 'loss': 0.07488958945032209, 'acc': 0.97265625}\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/100\n",
      " - 11s - loss: 0.1086 - acc: 0.9510 - val_loss: 0.1661 - val_acc: 0.9409\n",
      "Finished epoch: 42\n",
      "{'val_loss': 0.16609461325912672, 'val_acc': 0.9408740361429425, 'loss': 0.10606559257426423, 'acc': 0.9520958081452908}\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/100\n",
      " - 11s - loss: 0.0808 - acc: 0.9717 - val_loss: 0.1736 - val_acc: 0.9332\n",
      "Finished epoch: 43\n",
      "{'val_loss': 0.17363630691040452, 'val_acc': 0.9331619538807318, 'loss': 0.08084251871332526, 'acc': 0.9716796875}\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/100\n",
      " - 11s - loss: 0.0640 - acc: 0.9727 - val_loss: 0.1782 - val_acc: 0.9357\n",
      "Finished epoch: 44\n",
      "{'val_loss': 0.1782414301042385, 'val_acc': 0.9357326479681354, 'loss': 0.06395562115358189, 'acc': 0.97265625}\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/100\n",
      " - 11s - loss: 0.0640 - acc: 0.9795 - val_loss: 0.1766 - val_acc: 0.9383\n",
      "Finished epoch: 45\n",
      "{'val_loss': 0.1766274257306881, 'val_acc': 0.9383033420555389, 'loss': 0.06395333167165518, 'acc': 0.9794921875}\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/100\n",
      " - 11s - loss: 0.0759 - acc: 0.9688 - val_loss: 0.1872 - val_acc: 0.9357\n",
      "Finished epoch: 46\n",
      "{'val_loss': 0.18720186676035197, 'val_acc': 0.9357326479681354, 'loss': 0.07587280965526588, 'acc': 0.96875}\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/100\n",
      " - 11s - loss: 0.0842 - acc: 0.9637 - val_loss: 0.1901 - val_acc: 0.9383\n",
      "Finished epoch: 47\n",
      "{'val_loss': 0.19012437442887412, 'val_acc': 0.9383033420555389, 'loss': 0.08220363192691536, 'acc': 0.9650698600414984}\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/100\n",
      " - 11s - loss: 0.0729 - acc: 0.9756 - val_loss: 0.1762 - val_acc: 0.9409\n",
      "Finished epoch: 48\n",
      "{'val_loss': 0.17622101582720837, 'val_acc': 0.9408740361429425, 'loss': 0.07291881187120453, 'acc': 0.9755859375}\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "Epoch 50/100\n",
      " - 11s - loss: 0.0774 - acc: 0.9665 - val_loss: 0.1733 - val_acc: 0.9306\n",
      "Finished epoch: 49\n",
      "{'val_loss': 0.1733194789573895, 'val_acc': 0.9305912597933281, 'loss': 0.07393263185214616, 'acc': 0.9700598803584923}\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "Epoch 51/100\n",
      " - 11s - loss: 0.0587 - acc: 0.9775 - val_loss: 0.1805 - val_acc: 0.9306\n",
      "Finished epoch: 50\n",
      "{'val_loss': 0.18052778015712845, 'val_acc': 0.9305912597933281, 'loss': 0.05872086937597487, 'acc': 0.9775390625}\n",
      "\n",
      "Epoch 00051: val_loss did not improve\n",
      "Epoch 52/100\n",
      " - 11s - loss: 0.0421 - acc: 0.9873 - val_loss: 0.1831 - val_acc: 0.9332\n",
      "Finished epoch: 51\n",
      "{'val_loss': 0.18309117290538504, 'val_acc': 0.9331619538807318, 'loss': 0.042056673439219594, 'acc': 0.9873046875}\n",
      "\n",
      "Epoch 00052: val_loss did not improve\n",
      "Epoch 53/100\n",
      " - 11s - loss: 0.0613 - acc: 0.9775 - val_loss: 0.2046 - val_acc: 0.9177\n",
      "Finished epoch: 52\n",
      "{'val_loss': 0.2046042343644679, 'val_acc': 0.9177377893563101, 'loss': 0.06128156842896715, 'acc': 0.9775390625}\n",
      "\n",
      "Epoch 00053: val_loss did not improve\n",
      "Epoch 54/100\n",
      " - 11s - loss: 0.0667 - acc: 0.9727 - val_loss: 0.2152 - val_acc: 0.9203\n",
      "Finished epoch: 53\n",
      "{'val_loss': 0.21519798461759612, 'val_acc': 0.9203084834437137, 'loss': 0.06668050040025264, 'acc': 0.97265625}\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/100\n",
      " - 10s - loss: 0.0665 - acc: 0.9754 - val_loss: 0.1989 - val_acc: 0.9357\n",
      "Finished epoch: 54\n",
      "{'val_loss': 0.1988618887175631, 'val_acc': 0.9357326479681354, 'loss': 0.06409380910639277, 'acc': 0.97704590794569}\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 56/100\n",
      " - 11s - loss: 0.0599 - acc: 0.9756 - val_loss: 0.1962 - val_acc: 0.9357\n",
      "Finished epoch: 55\n",
      "{'val_loss': 0.19620200846066513, 'val_acc': 0.9357326479681354, 'loss': 0.059886394010391086, 'acc': 0.9755859375}\n",
      "\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 57/100\n",
      " - 11s - loss: 0.0549 - acc: 0.9844 - val_loss: 0.2054 - val_acc: 0.9357\n",
      "Finished epoch: 56\n",
      "{'val_loss': 0.20536654563213683, 'val_acc': 0.9357326479681354, 'loss': 0.05487353907665238, 'acc': 0.984375}\n",
      "\n",
      "Epoch 00057: val_loss did not improve\n",
      "Epoch 58/100\n",
      " - 10s - loss: 0.0474 - acc: 0.9844 - val_loss: 0.2082 - val_acc: 0.9357\n",
      "Finished epoch: 57\n",
      "{'val_loss': 0.20822597611073052, 'val_acc': 0.9357326479681354, 'loss': 0.04658691968002957, 'acc': 0.9840319361277445}\n",
      "\n",
      "Epoch 00058: val_loss did not improve\n",
      "Epoch 59/100\n",
      " - 11s - loss: 0.0507 - acc: 0.9805 - val_loss: 0.2227 - val_acc: 0.9306\n",
      "Finished epoch: 58\n",
      "{'val_loss': 0.2227029419650149, 'val_acc': 0.9305912597933281, 'loss': 0.05069142249703873, 'acc': 0.98046875}\n",
      "\n",
      "Epoch 00059: val_loss did not improve\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 11s - loss: 0.0643 - acc: 0.9854 - val_loss: 0.2153 - val_acc: 0.9383\n",
      "Finished epoch: 59\n",
      "{'val_loss': 0.21526750703857, 'val_acc': 0.9383033420555389, 'loss': 0.06431768939364702, 'acc': 0.9853515625}\n",
      "\n",
      "Epoch 00060: val_loss did not improve\n",
      "Epoch 61/100\n",
      " - 11s - loss: 0.0518 - acc: 0.9814 - val_loss: 0.2004 - val_acc: 0.9434\n",
      "Finished epoch: 60\n",
      "{'val_loss': 0.20035805761967343, 'val_acc': 0.9434447302303461, 'loss': 0.05182859123306116, 'acc': 0.9814453125}\n",
      "\n",
      "Epoch 00061: val_loss did not improve\n",
      "Epoch 62/100\n",
      " - 11s - loss: 0.0767 - acc: 0.9665 - val_loss: 0.2002 - val_acc: 0.9409\n",
      "Finished epoch: 61\n",
      "{'val_loss': 0.20024022827724564, 'val_acc': 0.9408740361429425, 'loss': 0.06989167800206623, 'acc': 0.9700598803584923}\n",
      "\n",
      "Epoch 00062: val_loss did not improve\n",
      "Epoch 63/100\n",
      " - 11s - loss: 0.0479 - acc: 0.9824 - val_loss: 0.2100 - val_acc: 0.9357\n",
      "Finished epoch: 62\n",
      "{'val_loss': 0.2099827470157324, 'val_acc': 0.9357326479681354, 'loss': 0.04787115612998605, 'acc': 0.982421875}\n",
      "\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 64/100\n",
      " - 11s - loss: 0.0448 - acc: 0.9805 - val_loss: 0.2036 - val_acc: 0.9383\n",
      "Finished epoch: 63\n",
      "{'val_loss': 0.2035612874594936, 'val_acc': 0.9383033420555389, 'loss': 0.044787601291318424, 'acc': 0.98046875}\n",
      "\n",
      "Epoch 00064: val_loss did not improve\n",
      "Epoch 65/100\n",
      " - 11s - loss: 0.0606 - acc: 0.9784 - val_loss: 0.2276 - val_acc: 0.9306\n",
      "Finished epoch: 64\n",
      "{'val_loss': 0.22757166118425698, 'val_acc': 0.9305912597933281, 'loss': 0.05796411102581881, 'acc': 0.9800399199217379}\n",
      "\n",
      "Epoch 00065: val_loss did not improve\n",
      "Epoch 66/100\n",
      " - 11s - loss: 0.0402 - acc: 0.9844 - val_loss: 0.2099 - val_acc: 0.9357\n",
      "Finished epoch: 65\n",
      "{'val_loss': 0.2098852716252246, 'val_acc': 0.9357326479681354, 'loss': 0.04023235177010065, 'acc': 0.984375}\n",
      "\n",
      "Epoch 00066: val_loss did not improve\n",
      "Epoch 67/100\n",
      " - 11s - loss: 0.0443 - acc: 0.9834 - val_loss: 0.2025 - val_acc: 0.9383\n",
      "Finished epoch: 66\n",
      "{'val_loss': 0.20247533894443268, 'val_acc': 0.9383033420555389, 'loss': 0.044301476526015904, 'acc': 0.9833984375}\n",
      "\n",
      "Epoch 00067: val_loss did not improve\n",
      "Epoch 68/100\n",
      " - 11s - loss: 0.0390 - acc: 0.9873 - val_loss: 0.2120 - val_acc: 0.9306\n",
      "Finished epoch: 67\n",
      "{'val_loss': 0.21203130475966053, 'val_acc': 0.9305912597933281, 'loss': 0.039027504637488164, 'acc': 0.9873046875}\n",
      "\n",
      "Epoch 00068: val_loss did not improve\n",
      "Epoch 69/100\n",
      " - 11s - loss: 0.0557 - acc: 0.9763 - val_loss: 0.2115 - val_acc: 0.9332\n",
      "Finished epoch: 68\n",
      "{'val_loss': 0.2115218371995617, 'val_acc': 0.9331619538807318, 'loss': 0.050611753797459746, 'acc': 0.9800399202786519}\n",
      "\n",
      "Epoch 00069: val_loss did not improve\n",
      "Epoch 70/100\n",
      " - 11s - loss: 0.0297 - acc: 0.9902 - val_loss: 0.2202 - val_acc: 0.9357\n",
      "Finished epoch: 69\n",
      "{'val_loss': 0.22023039711471695, 'val_acc': 0.9357326479681354, 'loss': 0.029705619337619282, 'acc': 0.990234375}\n",
      "\n",
      "Epoch 00070: val_loss did not improve\n",
      "Epoch 71/100\n",
      " - 11s - loss: 0.0383 - acc: 0.9881 - val_loss: 0.2306 - val_acc: 0.9254\n",
      "Finished epoch: 70\n",
      "{'val_loss': 0.23061582905774253, 'val_acc': 0.925449871618521, 'loss': 0.0340093005366787, 'acc': 0.9900199598418976}\n",
      "\n",
      "Epoch 00071: val_loss did not improve\n",
      "Epoch 72/100\n",
      " - 11s - loss: 0.0438 - acc: 0.9854 - val_loss: 0.2314 - val_acc: 0.9280\n",
      "Finished epoch: 71\n",
      "{'val_loss': 0.23142587111970758, 'val_acc': 0.9280205657059245, 'loss': 0.043778262654086575, 'acc': 0.9853515625}\n",
      "\n",
      "Epoch 00072: val_loss did not improve\n",
      "Epoch 73/100\n"
     ]
    }
   ],
   "source": [
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsprop = keras.optimizers.RMSprop(lr=2e-5)\n",
    "train_util.train(model, train_gen, val_gen, steps_per_epoch=32, loss='categorical_crossentropy', optimizer=rmsprop )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('./log/2018_0728_1233/best_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389/389 [==============================] - 6s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_test = loaded_model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.9500689e-17],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [2.5636387e-18],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.8971737e-03],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.9500689e-17],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.9500689e-17],\n",
       "       [1.9500689e-17],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.3152780e-37],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.9500689e-17],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.9500689e-17],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [4.1197317e-35],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.9500689e-17],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.9500689e-17],\n",
       "       [0.0000000e+00],\n",
       "       [2.5014184e-09],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [3.2686514e-01],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [9.9992943e-01],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.7609157e-30],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dense_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f0ca4e948b39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mdel\u001b[0m  \u001b[0mdense_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mdel\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dense_model' is not defined"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "del  dense_model\n",
    "del  model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
